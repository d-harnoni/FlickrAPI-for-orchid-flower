{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import traceback\n",
    "import time\n",
    "import sys\n",
    "import json\n",
    "from random import randint\n",
    "from urllib.request import urlretrieve\n",
    "import flickrapi\n",
    "# API settings\n",
    "flickr_api_key = 'xxx' #change 'xxx' with your flickr_api_key\n",
    "secret_key = 'xxx' #change 'xxx' with your secret_key\n",
    "\n",
    "def download_flickr_photos(keywords, size='medium', max_nb_img=-1):\n",
    "    \n",
    "    \"\"\"\n",
    "    Downloads images based on keyword search on the Flickr website\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    keywords : string, list of strings\n",
    "        Keyword to search for or a list of keywords should be given.\n",
    "    size : one of the following strings 'thumbnail', 'square', 'medium', default: 'original'.\n",
    "        Size of the image to download. In this function we only provide\n",
    "        four options. More options are explained at \n",
    "        http://librdf.org/flickcurl/api/flickcurl-searching-search-extras.html\n",
    "    max_nb_img : int, default: -1\n",
    "        Maximum number of images per keyword to download. If given a value of -1, all images\n",
    "        will be downloaded\n",
    "    \n",
    "    Returns\n",
    "    ------\n",
    "    Images found based on the keyword are saved in a separate subfolder.\n",
    "    \n",
    "    Notes\n",
    "    -----\n",
    "    This function uses the Python package flickrapi and its walk method. \n",
    "    FlickrAPI.walk has same parameters as FlickrAPI.search\n",
    "    http://www.flickr.com/services/api/flickr.photos.search.html\n",
    "    \n",
    "    To use the Flickr API a set of API keys needs to be created on \n",
    "    https://www.flickr.com/services/api/misc.api_keys.html\n",
    "    \"\"\"\n",
    "    if not (isinstance(keywords, str) or isinstance(keywords, list)):\n",
    "        raise AttributeError('keywords must be a string or a list of strings')\n",
    "        \n",
    "    if not (size in ['thumbnail', 'square', 'medium', 'original']):\n",
    "        raise AttributeError('size must be \"thumbnail\", \"square\", \"medium\" or \"original\"')\n",
    "                             \n",
    "    if not (max_nb_img == -1 or (max_nb_img > 0 and isinstance(max_nb_img, int))):\n",
    "        raise AttributeError('max_nb_img must be an integer greater than zero or equal to -1')\n",
    "    \n",
    "    flicker = flickrapi.FlickrAPI (flickr_api_key, secret_key, format = 'parsed-json')\n",
    "    \n",
    "    if isinstance(keywords, str):\n",
    "        keywords_list = []\n",
    "        keywords_list.append(keywords)\n",
    "    else:\n",
    "        keywords_list = keywords\n",
    "        \n",
    "    if size == 'thumbnail':\n",
    "        size_url = 'url_t'\n",
    "    elif size == 'square':\n",
    "        size_url = 'url_q'\n",
    "    elif size == 'medium':\n",
    "        size_url = 'url_c'\n",
    "    elif size == 'original':\n",
    "        size_url = 'url_o'\n",
    "    \n",
    "    for keyword in keywords_list: \n",
    "        count = 0\n",
    "        if __name__ == '__main__':   \n",
    "            print ('accessing ...')\n",
    "            response = flicker.photos.search (\n",
    "                text = keyword,\n",
    "                media = 'photos',\n",
    "                sort = 'relevance',\n",
    "                license = '1,2,4,5',\n",
    "                per_page = 500,\n",
    "                extras = 'url_m, date_taken, license, owner_name, geo')\n",
    "            photos = response ['photos']\n",
    "            try:\n",
    "                out_dirpath = os.path.join ('image_data', keyword)\n",
    "                os.makedirs (out_dirpath, exist_ok = True)               \n",
    "                for photo in photos ['photo']:\n",
    "                    t = randint(1, 3)\n",
    "                    time.sleep(t)\n",
    "                    count += 1\n",
    "                    if max_nb_img != -1:\n",
    "                        if count > max_nb_img:\n",
    "                            print('Reached maximum number of images to download')\n",
    "                            break\n",
    "                    url = photo ['url_m']\n",
    "                    out_path = os.path.join (out_dirpath, str(count) + '_'+ photo ['id'] + '.jpg')\n",
    "                    print ('getting image ...'+ str(count)  + '_' + url)\n",
    "                    urlretrieve (url, out_path)\n",
    "            except Exception as e:\n",
    "                traceback.print_exc ()\n",
    "            with open ('photo _ {}. json'.format (keyword),'w') as f:\n",
    "                json.dump (photos, f, sort_keys = True, indent = 4)\n",
    "            print(\"Total images downloaded:\", str(count) + '_' + keyword)\n",
    "        \n",
    "flowers = ['CypripediumÂ guttatum','Corallorhiza mertensiana','Corallorhiza wisteriana','Encyclia tampensis','Oeceoclades maculata','Triphora craigheadii']\n",
    "for flower in flowers:\n",
    "    download_flickr_photos(flower)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
